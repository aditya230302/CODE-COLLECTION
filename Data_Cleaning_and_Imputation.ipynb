{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Excellent! Let's dive into a **complete guide to data cleaning**, with **all key steps** and **code examples** in Python using `pandas`, `numpy`, and `sklearn`.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… What is Data Cleaning?\n",
        "\n",
        "**Data cleaning** is the process of **detecting and correcting (or removing)** errors, inconsistencies, and inaccuracies in the data to improve its quality before analysis or modeling.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”§ A. DATA CLEANING CHECKLIST (with CODE)\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ 1. **Load and Understand the Data**\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"data.csv\")  # or pd.read_excel, pd.read_json, etc.\n",
        "print(df.shape)\n",
        "print(df.dtypes)\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ 2. **Identify and Handle Missing Values**\n",
        "\n",
        "#### âœ… a. Detect Missing Values\n",
        "\n",
        "```python\n",
        "df.isnull().sum()         # Total missing per column\n",
        "df.isnull().mean()*100    # Percentage missing\n",
        "```\n",
        "\n",
        "#### âœ… b. Drop Missing Values\n",
        "\n",
        "```python\n",
        "df.dropna(inplace=True)  # Drop rows with any missing values\n",
        "```\n",
        "\n",
        "#### âœ… c. Fill Missing Values\n",
        "\n",
        "```python\n",
        "df['Age'].fillna(df['Age'].mean(), inplace=True)        # Numeric: mean\n",
        "df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)  # Categorical: mode\n",
        "```\n",
        "\n",
        "#### âœ… d. Interpolation\n",
        "\n",
        "```python\n",
        "df['Temperature'] = df['Temperature'].interpolate(method='linear')\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ 3. **Handle Duplicates**\n",
        "\n",
        "```python\n",
        "df.duplicated().sum()\n",
        "df.drop_duplicates(inplace=True)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ 4. **Fix Data Types**\n",
        "\n",
        "```python\n",
        "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "df['Age'] = df['Age'].astype('int')\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ 5. **Standardize Categorical Values**\n",
        "\n",
        "```python\n",
        "df['Gender'] = df['Gender'].str.lower().str.strip()\n",
        "df['Gender'] = df['Gender'].replace({'m': 'male', 'f': 'female'})\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ 6. **Outlier Detection and Treatment**\n",
        "\n",
        "#### âœ… a. Z-Score Method\n",
        "\n",
        "```python\n",
        "from scipy.stats import zscore\n",
        "\n",
        "z_scores = zscore(df['Income'])\n",
        "df = df[(abs(z_scores) < 3)]\n",
        "```\n",
        "\n",
        "#### âœ… b. IQR Method\n",
        "\n",
        "```python\n",
        "Q1 = df['Income'].quantile(0.25)\n",
        "Q3 = df['Income'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "df = df[(df['Income'] >= Q1 - 1.5 * IQR) & (df['Income'] <= Q3 + 1.5 * IQR)]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ 7. **Handle Inconsistent Formatting**\n",
        "\n",
        "#### âœ… a. Remove Whitespace & Special Characters\n",
        "\n",
        "```python\n",
        "df['Name'] = df['Name'].str.strip().str.replace('[^a-zA-Z ]', '', regex=True)\n",
        "```\n",
        "\n",
        "#### âœ… b. Fix Case Sensitivity\n",
        "\n",
        "```python\n",
        "df['City'] = df['City'].str.title()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ 8. **Drop Unnecessary Columns**\n",
        "\n",
        "```python\n",
        "df.drop(columns=['Unnamed: 0', 'Temp_ID'], inplace=True)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ 9. **Detect and Handle Inconsistent Units or Scales**\n",
        "\n",
        "```python\n",
        "# Convert \"cm\" to \"m\" for height\n",
        "df['Height_m'] = df['Height_cm'] / 100\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ 10. **Validate Business Rules**\n",
        "\n",
        "#### âœ… Example:\n",
        "\n",
        "```python\n",
        "# Salary should not be negative\n",
        "df = df[df['Salary'] >= 0]\n",
        "\n",
        "# Age should be within realistic range\n",
        "df = df[(df['Age'] > 0) & (df['Age'] < 120)]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ 11. **Text Cleaning (for NLP)**\n",
        "\n",
        "```python\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)             # Remove URLs\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)       # Remove special characters\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "df['Clean_Review'] = df['Review'].apply(clean_text)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… BONUS: Automate Cleaning with Pipelines (Scikit-learn)\n",
        "\n",
        "```python\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "X_cleaned = pipeline.fit_transform(df[['Age', 'Salary']])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Summary Table\n",
        "\n",
        "| Task                 | Tools/Methods                            |\n",
        "| -------------------- | ---------------------------------------- |\n",
        "| Missing values       | `dropna`, `fillna`, `interpolate`        |\n",
        "| Duplicates           | `drop_duplicates`                        |\n",
        "| Data type fixing     | `astype`, `to_datetime`                  |\n",
        "| Categorical cleanup  | `.str.lower()`, `.replace()`, `.strip()` |\n",
        "| Outlier handling     | Z-score, IQR                             |\n",
        "| Inconsistent formats | Regex, `.str.replace()`, `.title()`      |\n",
        "| Text cleanup         | Regex, `re`, `nltk`                      |\n",
        "| Column reduction     | `drop(columns=[...])`                    |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "vDM8-rUkYVDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## âœ… What is KMeans Imputer?\n",
        "\n",
        "Instead of filling missing values with the **mean/median** (which may ignore feature relationships), **KMeans Imputer**:\n",
        "\n",
        "* Groups similar rows using **K-Means clustering**.\n",
        "* Fills missing values using the **mean of the feature within its cluster**.\n",
        "\n",
        "Itâ€™s especially useful when:\n",
        "\n",
        "* Your data has **structured patterns** (e.g., customer segments, behavior groups).\n",
        "* You're dealing with **numerical features**.\n",
        "* You want a **smarter imputation** than global averages.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ› ï¸ How It Works (Step-by-Step)\n",
        "\n",
        "1. Use only rows with no missing values to **train the KMeans model**.\n",
        "2. Predict clusters for all rows (including missing).\n",
        "3. Impute missing values using the **cluster-wise mean** of each feature.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Code Example: KMeans Imputer (Manual Implementation)\n",
        "\n",
        "### ðŸ”¹ Step 1: Import Libraries\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "```\n",
        "\n",
        "### ðŸ”¹ Step 2: Sample Data\n",
        "\n",
        "```python\n",
        "# Sample data with missing values\n",
        "df = pd.DataFrame({\n",
        "    'Age': [25, 27, np.nan, 22, 35, np.nan],\n",
        "    'Income': [50000, 54000, 52000, 48000, np.nan, 60000],\n",
        "    'Spending': [200, 220, 210, 190, 250, np.nan]\n",
        "})\n",
        "```\n",
        "\n",
        "### ðŸ”¹ Step 3: Scale & Separate Complete Rows\n",
        "\n",
        "```python\n",
        "scaler = StandardScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# Separate rows with and without missing values\n",
        "df_complete = df_scaled.dropna()\n",
        "df_missing = df_scaled[df_scaled.isnull().any(axis=1)]\n",
        "```\n",
        "\n",
        "### ðŸ”¹ Step 4: Fit KMeans on Complete Rows\n",
        "\n",
        "```python\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "df_complete['cluster'] = kmeans.fit_predict(df_complete)\n",
        "```\n",
        "\n",
        "### ðŸ”¹ Step 5: Assign Cluster to Incomplete Rows\n",
        "\n",
        "```python\n",
        "# Fill missing temporarily for distance calculation\n",
        "temp_imputer = SimpleImputer(strategy='mean')\n",
        "temp_data = temp_imputer.fit_transform(df_scaled)\n",
        "\n",
        "# Predict clusters for all rows (including missing)\n",
        "df_scaled['cluster'] = kmeans.predict(temp_data)\n",
        "```\n",
        "\n",
        "### ðŸ”¹ Step 6: Impute Missing with Cluster Means\n",
        "\n",
        "```python\n",
        "# Inverse scaling to get back original values\n",
        "df_scaled_original = pd.DataFrame(scaler.inverse_transform(df_scaled.drop(columns=['cluster'])), columns=df.columns)\n",
        "\n",
        "# Add cluster column back\n",
        "df_scaled_original['cluster'] = df_scaled['cluster']\n",
        "\n",
        "# Fill missing with cluster-wise mean\n",
        "for col in df.columns:\n",
        "    for cluster in df_scaled_original['cluster'].unique():\n",
        "        mask = (df_scaled_original['cluster'] == cluster) & (df_scaled_original[col].isnull())\n",
        "        mean_value = df_scaled_original.loc[df_scaled_original['cluster'] == cluster, col].mean()\n",
        "        df_scaled_original.loc[mask, col] = mean_value\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Result\n",
        "\n",
        "```python\n",
        "print(df_scaled_original.drop(columns=['cluster']))\n",
        "```\n",
        "\n",
        "Now youâ€™ll have a **clean DataFrame** with missing values **filled intelligently based on cluster behavior**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ” When to Use KMeans Imputer?\n",
        "\n",
        "| Use Case                    | Suitability            |\n",
        "| --------------------------- | ---------------------- |\n",
        "| Numerical data              | âœ… Ideal                |\n",
        "| Obvious clustering patterns | âœ… Best case            |\n",
        "| Categorical data            | âŒ Not ideal            |\n",
        "| Mixed data types            | âš ï¸ Needs preprocessing |\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Alternative: Use `FancyImpute`'s KMeansImputer (3rd-party lib)\n",
        "\n",
        "```bash\n",
        "pip install fancyimpute\n",
        "```\n",
        "\n",
        "```python\n",
        "from fancyimpute import KNN, IterativeImputer, KMeans\n",
        "\n",
        "kmeans_imputer = KMeans(n_clusters=2)\n",
        "df_imputed = kmeans_imputer.fit_transform(df.values)\n",
        "```\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "RlTfJYuYYdiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ðŸ§¾ Table of Contents\n",
        "\n",
        "1. [Simple Imputation Methods](#1)\n",
        "2. [Statistical Imputation](#2)\n",
        "3. [Model-Based Imputation](#3)\n",
        "4. [KNN Imputation](#4)\n",
        "5. [KMeans Imputation](#5)\n",
        "6. [Multivariate Imputation (MICE)](#6)\n",
        "7. [Deep Learning Imputation](#7)\n",
        "8. [Domain-Specific or Custom Imputation](#8)\n",
        "9. [Dropping Missing Data](#9)\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ <a name=\"1\"></a>1. **Simple Imputation Methods**\n",
        "\n",
        "### âœ… a. Fill with Constant\n",
        "\n",
        "```python\n",
        "df['Gender'].fillna('Unknown', inplace=True)\n",
        "df['Age'].fillna(0, inplace=True)\n",
        "```\n",
        "\n",
        "### âœ… b. Fill with Mean/Median/Mode\n",
        "\n",
        "```python\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "mean_imputer = SimpleImputer(strategy='mean')\n",
        "df[['Age']] = mean_imputer.fit_transform(df[['Age']])\n",
        "\n",
        "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
        "df[['Gender']] = mode_imputer.fit_transform(df[['Gender']])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ <a name=\"2\"></a>2. **Statistical/Group-Based Imputation**\n",
        "\n",
        "### âœ… a. Fill with Grouped Mean\n",
        "\n",
        "```python\n",
        "df['Age'] = df.groupby('Gender')['Age'].transform(lambda x: x.fillna(x.mean()))\n",
        "```\n",
        "\n",
        "### âœ… b. Interpolation (for time series)\n",
        "\n",
        "```python\n",
        "df['Temperature'] = df['Temperature'].interpolate(method='linear')  # or 'time', 'polynomial', etc.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ <a name=\"3\"></a>3. **Model-Based Imputation**\n",
        "\n",
        "Train a **supervised ML model** (e.g., regression) to predict missing values.\n",
        "\n",
        "### âœ… a. Predict Age with Random Forest\n",
        "\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Separate known and unknown\n",
        "known = df[df['Age'].notnull()]\n",
        "unknown = df[df['Age'].isnull()]\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "model.fit(known[['Income', 'Spending']], known['Age'])\n",
        "\n",
        "df.loc[df['Age'].isnull(), 'Age'] = model.predict(unknown[['Income', 'Spending']])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ <a name=\"4\"></a>4. **KNN Imputation**\n",
        "\n",
        "Fills missing values using the average of the k-nearest neighbors.\n",
        "\n",
        "```python\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=3)\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "```\n",
        "\n",
        "âœ… Works well when features are **correlated**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ <a name=\"5\"></a>5. **KMeans Imputation (Cluster-Based)**\n",
        "\n",
        "Use KMeans to cluster similar rows and impute missing values with **cluster-wise means**.\n",
        "\n",
        "```python\n",
        "pip install fancyimpute\n",
        "\n",
        "kmeans_imputer = KMeans(n_clusters=2)\n",
        "df_imputed = kmeans_imputer.fit_transform(df.values)\n",
        "```\n",
        "\n",
        "âœ… Best when dataset shows **natural clusters or segmentation**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ <a name=\"6\"></a>6. **Multivariate Imputation (MICE - Iterative)**\n",
        "\n",
        "Uses chained equations to model each feature as a function of the others.\n",
        "\n",
        "```python\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "imputer = IterativeImputer(random_state=42)\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "```\n",
        "\n",
        "âœ… Suitable for **complex data with multiple correlated features**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ <a name=\"7\"></a>7. **Deep Learning Imputation (Autoencoders)**\n",
        "\n",
        "Train an autoencoder to learn feature representations and reconstruct missing values.\n",
        "\n",
        "```python\n",
        "# Typically done with TensorFlow or PyTorch; requires custom pipeline\n",
        "# Pseudo-code:\n",
        "# - Normalize\n",
        "# - Train autoencoder to reconstruct input\n",
        "# - Use reconstruction to fill in missing\n",
        "```\n",
        "\n",
        "âœ… Ideal for large datasets, high dimensionality, or image/NLP/tabular hybrids.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ <a name=\"8\"></a>8. **Domain-Specific or Custom Imputation**\n",
        "\n",
        "Examples:\n",
        "\n",
        "* Fill missing temperatures with seasonal averages\n",
        "* Fill missing product prices with category-wise medians\n",
        "* NLP: Fill missing text fields with `\"\"` or `\"unknown\"`\n",
        "\n",
        "```python\n",
        "# Example: fill NaNs in 'Salary' based on JobTitle\n",
        "df['Salary'] = df.groupby('JobTitle')['Salary'].transform(lambda x: x.fillna(x.median()))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ <a name=\"9\"></a>9. **Dropping Missing Values (When Safe)**\n",
        "\n",
        "```python\n",
        "df.dropna(axis=0, how='any', inplace=True)   # Drop rows with any missing values\n",
        "df.dropna(axis=1, how='all', inplace=True)   # Drop columns where all values are NaN\n",
        "```\n",
        "\n",
        "âœ… Only recommended when:\n",
        "\n",
        "* Dataset is large\n",
        "* Affected rows/columns are few\n",
        "* Data is missing completely at random (MCAR)\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary Table\n",
        "\n",
        "| Method                  | Type           | Good For                                  |\n",
        "| ----------------------- | -------------- | ----------------------------------------- |\n",
        "| Mean/Median/Mode        | Simple         | Basic numeric/categorical imputation      |\n",
        "| Grouped Mean            | Statistical    | Data grouped by category (e.g. by gender) |\n",
        "| Interpolation           | Statistical    | Time series                               |\n",
        "| KNN                     | Distance-based | Correlated numeric data                   |\n",
        "| KMeans                  | Cluster-based  | Segmented data                            |\n",
        "| IterativeImputer (MICE) | Model-based    | Multivariate imputation                   |\n",
        "| Regression/Tree Model   | Supervised     | Targeted missing value prediction         |\n",
        "| Autoencoder             | Deep Learning  | Complex, high-dimensional data            |\n",
        "| Drop NA                 | Last resort    | Sparse missing data or early EDA          |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "ioSk-DaSYpX0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvA1ONT5YQPL"
      },
      "outputs": [],
      "source": []
    }
  ]
}