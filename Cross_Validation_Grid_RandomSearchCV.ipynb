{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a38cd02b-e790-40b4-a6e9-c2c843d4e238",
   "metadata": {},
   "source": [
    "**general-purpose cross-validation code** using **`KFold` from scikit-learn**, which you can apply to **any model** (e.g., Logistic Regression, Decision Tree, Random Forest, XGBoost, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### **General K-Fold Cross-Validation Code**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def cross_validate_model(model, X, y, k=5):\n",
    "    \"\"\"\n",
    "    Performs K-Fold cross-validation on any sklearn-compatible model.\n",
    "    \n",
    "    Parameters:\n",
    "        model: the machine learning model (e.g., RandomForestClassifier()).\n",
    "        X: feature matrix (numpy array or DataFrame).\n",
    "        y: target labels.\n",
    "        k: number of folds (default: 5).\n",
    "        \n",
    "    Returns:\n",
    "        List of accuracy scores for each fold.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_val)\n",
    "\n",
    "        acc = accuracy_score(y_val, predictions)\n",
    "        scores.append(acc)\n",
    "        print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n",
    "\n",
    "    print(f\"\\nAverage Accuracy: {np.mean(scores):.4f}\")\n",
    "    return scores\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Usage Example**\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load sample dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Initialize model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Run cross-validation\n",
    "cross_validate_model(model, X, y, k=5)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **You Can Use This With:**\n",
    "- `RandomForestClassifier`\n",
    "- `LogisticRegression`\n",
    "- `SVC`, `KNeighborsClassifier`\n",
    "- `XGBClassifier`, `LGBMClassifier`\n",
    "- Even regression models with minor tweaks (just change the metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d748c-4dc7-4f3d-91a8-fab3dab1b81b",
   "metadata": {},
   "source": [
    "---\n",
    "There **is an inbuilt method** in scikit-learn for cross-validation:\n",
    "\n",
    "### **1. `cross_val_score()`** – the most commonly used inbuilt function for classification and regression models.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example: Classification with `cross_val_score()`**\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Perform 5-fold CV\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", scores)\n",
    "print(\"Average Accuracy:\", scores.mean())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Parameters**\n",
    "- `model`: any scikit-learn compatible model\n",
    "- `X, y`: features and target\n",
    "- `cv`: number of folds (e.g., `cv=5`)\n",
    "- `scoring`: metric (e.g., `'accuracy'`, `'f1'`, `'roc_auc'`, `'neg_mean_squared_error'`)\n",
    "\n",
    "---\n",
    "\n",
    "### **2. `cross_validate()`** – more flexible (returns multiple scores)\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scores = cross_validate(LogisticRegression(), X, y, cv=5,\n",
    "                        scoring=['accuracy', 'f1_macro'],\n",
    "                        return_train_score=True)\n",
    "\n",
    "print(scores)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119e2b5d-3544-4a31-95fa-a24fe1a98572",
   "metadata": {},
   "source": [
    "## **Different types of cross-validation**.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Cross-Validation (Generic) vs. Specific Techniques**\n",
    "There are different types of **cross-validation**, such as:\n",
    "\n",
    "| Type | Description |\n",
    "|------|-------------|\n",
    "| **K-Fold Cross-Validation** | Splits data into *K* folds. Trains on K-1, tests on 1, repeated K times. |\n",
    "| **Stratified K-Fold** | Same as K-Fold but maintains class distribution in each fold (for classification). |\n",
    "| **Leave-One-Out (LOO)** | Each sample is its own test set. Very exhaustive. |\n",
    "| **Repeated K-Fold** | K-Fold repeated multiple times with different splits. |\n",
    "| **TimeSeriesSplit** | Used for time series data. Maintains temporal order. |\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **cross_val_score() vs. Manual Cross-Validation**\n",
    "- `cross_val_score()` is an **inbuilt helper function**.\n",
    "- Manual K-Fold using `KFold().split()` gives you more **flexibility** (e.g., saving models per fold, advanced metrics, visualizations, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Training Set Validation vs. Cross-Validation**\n",
    "- A **train/validation/test split** uses fixed splits (e.g., 70/20/10).\n",
    "- **Cross-validation** dynamically rotates validation folds for more **robust performance evaluation**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff333df9-a8f7-4aeb-935e-785c334c471f",
   "metadata": {},
   "source": [
    "These are **three core techniques** used in machine learning model evaluation and hyperparameter tuning. Here’s a clear breakdown:\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Cross-Validation (CV)**\n",
    "\n",
    "### **What It Is:**\n",
    "Cross-validation is a **model evaluation** technique used to assess how well your model generalizes to unseen data.\n",
    "\n",
    "### **How It Works:**\n",
    "- Data is split into `k` folds.\n",
    "- The model trains on `k-1` folds and validates on the remaining 1.\n",
    "- This process repeats `k` times, and the average score is computed.\n",
    "\n",
    "### **Use Case:**\n",
    "- Evaluate the performance of a model.\n",
    "- Detect overfitting or underfitting.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Grid Search (`GridSearchCV`)**\n",
    "\n",
    "### **What It Is:**\n",
    "A **hyperparameter tuning** method that exhaustively tries all combinations of a given parameter grid.\n",
    "\n",
    "### **How It Works:**\n",
    "- You define a grid of hyperparameters.\n",
    "- For each combination, it uses **cross-validation** to evaluate the model.\n",
    "- Returns the combination with the best score.\n",
    "\n",
    "### **Use Case:**\n",
    "- When you want **best hyperparameters** and can afford the time/computation cost.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [50, 100], 'max_depth': [5, 10]}\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Random Search (`RandomizedSearchCV`)**\n",
    "\n",
    "### **What It Is:**\n",
    "A **faster alternative** to Grid Search that randomly selects combinations of parameters to try.\n",
    "\n",
    "### **How It Works:**\n",
    "- Randomly samples a **fixed number** of parameter combinations from the grid.\n",
    "- Uses **cross-validation** to evaluate each.\n",
    "- More efficient when the parameter space is large.\n",
    "\n",
    "### **Use Case:**\n",
    "- When the search space is big or Grid Search is too slow.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {'n_estimators': randint(50, 200), 'max_depth': randint(3, 15)}\n",
    "rand_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist, n_iter=10, cv=5)\n",
    "rand_search.fit(X, y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Summary Table**\n",
    "\n",
    "| Feature                     | Cross-Validation        | GridSearchCV               | RandomizedSearchCV           |\n",
    "|----------------------------|--------------------------|-----------------------------|-------------------------------|\n",
    "| **Purpose**                | Evaluate model           | Tune hyperparameters        | Tune hyperparameters          |\n",
    "| **Search Type**            | None                     | Exhaustive                  | Random sampling               |\n",
    "| **Uses Cross-Validation**  | Yes                      | Yes                         | Yes                           |\n",
    "| **Speed**                  | Fast                     | Slow (expensive)            | Faster than GridSearchCV      |\n",
    "| **Best For**               | General model evaluation | Small hyperparam spaces     | Large hyperparam spaces       |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc54f4-7652-4f6c-80ba-e083747cb265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
